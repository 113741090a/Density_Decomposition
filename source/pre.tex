\section{Preliminaries}
\label{sec:prelim}


\noindent \textbf{Weighted Hypergraph and Bipartite Graph Interpretation.}
We consider a weighted hypergraph $H = (V, E; w)$ with a node set $V$ and a hyperedge set $E \subseteq 2^V$, where both nodes and hyperedges have positive weights assigned by the function $w: V \cup E \rightarrow \R_+$. Given $H$, we primarily work with the induced vertex-weighted bipartite graph $G = (E, V; \mcal{F}; w)$, with bipartition vertex sets $E$ and $V$, and edges $\mcal{F} \subseteq E \times V$, such that $(e, v) \in \mcal{F}$ \emph{iff} the hyperedge~$e$ in~$H$ contains the node~$v$. The vertices in $G$ retain their weights $w$ from $H$. To avoid degenerate cases, we assume that every vertex in $G$ has at least one neighbor in~$\mcal{F}$.


\noindent \textbf{Closed Neighborhood and Density.}
Given a non-empty $S \subseteq V$ on one side, its \emph{closed neighborhood} $\mcal{F}[S]$ is the collection of hyperedges containing only nodes within $S$, or equivalently:


$\mcal{F}[S] := \{e \in E: (e, v) \in \mcal{F} \implies v \in S\}$.

The density of $S$ is defined as  $\rho(S) := \frac{w(\mcal{F}[S])}{w(S)}$. 


%its \emph{open neighborhood} $S \subseteq \Ib$ consists of vertices on the other side that have at least one neighbor in $S$, i.e., $\mcal{F}(S) := \{j \in \Iob: \exists i \in S, i \sim j\}$. Its \emph{closed neighborhood} is $\mcal{F}[S] := \{j \in \mcal{F}(S): \mcal{F}(\{j\}) \subseteq S\}$, i.e., a vertex~$j$ is in $\mcal{F}[S]$ \emph{iff} it has at least one neighbor and all its neighbors are contained in~$S$.

%

\ignore{
	\noindent \emph{Extension to Empty Set.}
	In some of our applications, it makes sense to have isolated vertices
	in the input instance.
	For $\emptyset \subseteq \Ib$, 
	we extend $\mcal{F}(\emptyset) = \mcal{F}[\emptyset] :=
	\{j \in \Iob: \forall i \in \Ib, 
	j \not\sim i\}$.
	For the purpose of defining $\rho(\emptyset)$,
	we use the convention that $\frac{0}{0} = 0$ and 
	$\frac{x}{0} = + \infty$ for $x > 0$.
}

\begin{definition}[(Maximal) Densest Subset]
	\label{defn:densest}
	A subset $S \subseteq V$ is a densest subset
	if it attains $\max_{S \subseteq V} \rho(S)$.
	
	It is known that 
	the maximal densest subset (with respect to set inclusion) in $V$ is unique
	and contains all densest subsets.
\end{definition}

\ignore{
	The following fact characterizes a property of maximal densest subset~\cite[Lemma 4.1]{DBLP:conf/wsdm/BalalauBCGS15}.
	
	\begin{fact}
		With respect to set inclusion,
		the maximal densest subset in $\Ib$ is unique
		and contains all densest subsets.
		%
		%The maximal densest vertex-subset of an instance $G = (\Izero, \Ione; \mcal{F}; w)$ is unique and contains all densest vertex-subset of $G$.
	\end{fact}
}

%The definition of residual bipartite graph is instrumental in the definition of our vertex-density-friendly decomposition. 

\begin{definition}[Sub-Instance]
Given a bipartite instance $(E, V; \mcal{F}; w)$, the subsets $E' \subseteq E$ and $V' \subseteq V$ naturally induce a sub-instance $(E', V'; \mcal{F}'; w')$, where $\mcal{F}'$ is the restriction of $\mcal{F}$ to $E' \times V'$, and $w'$ is the restriction of $w$ to $E' \cup V'$.

When the context is clear, we may denote the sub-instance as $(E', V')$, omitting $\mcal{F}'$ and $w'$ from the notation.
\end{definition}

%For ease of presentation, we give an alternative constructive definition for the locally-dense decomposition as follows.

The following definition is essentially the same as the density decomposition of a hypergraph in~\cite{DBLP:conf/www/DanischCS17}. 

\begin{definition}[Hypergraph Density Decomposition]\label{def:decomposition}
	Given a bipartite instance $(E, V; \mcal{F}; w)$,
	its density decomposition is a sequence of pairs
	$\{(A_\ell, B_\ell)\}_{\ell \geq 1}$,
	where $E = \cup_\ell A_\ell$ and $V = \cup_\ell B_\ell$
	form disjoint unions of the corresponding subsets.
	This decomposition is generated by the following iterative process, which also produces a density vector $\rho_* \in \R_+^V$.
	
		
	Initially, we set $G_0 := (E, V; \mcal{F})$ to be the original given instance, and initialize $\ell = 0$.
	
	\begin{enumerate}
		
		\item If $G_{\ell} =
		(E_{\ell}, V_{\ell}; \mcal{F}_{\ell})$ contains no vertex, the process stops.
		
		\item Otherwise, let $B_{\ell+1}$ be the maximal densest subset in $G_{\ell}$.
		
		Define  $A_{\ell+1} := \mcal{F}_\ell[B_{\ell+1}]$,
		and its density $\rho_{\ell+1} := \frac{w(A_{\ell+1})}{w(B_{\ell+1})}$.
		
		For each $u \in B_{\ell+1}$, set $\rho_*(u) := \rho_{\ell+1}$.
		
		\item Let $G_{\ell+1}$ be the sub-instance induced by removing $A_{\ell+1}$ and
		$B_{\ell+1}$ from $G_{\ell}$, where edges in $\mcal{F}_\ell$ incident to removed vertices are also deleted.
		
		Increment $\ell$ by $1$ and proceed to the next iteration.
		
	\end{enumerate}
\end{definition} 


\ignore{
	\begin{remark}[Isolated elements]
		Observe that isolated hyperedges in $E$ should appear at the beginning of the decomposition sequence. 
		Isolated hypernodes should appear at the end of the decomposition sequence. 
		
		In the rest of this section, we may assume that isolated elements are removed from the instance.
	\end{remark}
}

\noindent \textbf{Problem Definition. }(\textit{Hypergraph Density Decomposition Problem})
Given a hypergraph instance $G = (E, V; \mcal{F}; w)$, compute the density vector $\rho_* \in \R^V$ as defined above.

Note that the correct density vector $\rho_*$ naturally partitions $V$ into $\{B_\ell\}_\ell$ according to density values, from which the sets $\{A_\ell\}_\ell$ are readily determined. Therefore, our primary objective is to compute or approximate the density vector.

In this work, we explore approximate iterative algorithms for the density decomposition problem. To evaluate the accuracy of an approximate vector $\widehat{\rho}$ compared to the target $\rho_*$, we employ the following metrics.



%global and local
\begin{definition}[Global vs Local Error]
	\label{defn:error}
	We consider the following error metrics to evaluate an approximate vector $\widehat{\rho}$ with respect to the target $\rho_* \in \R^V$:

	\begin{compactitem}
		
		\item \emph{Global error} (with respect to $\| \cdot \|_2$-norm):
		$\frac{\|\rho_* - \widehat{\rho}\|_2}{\|\rho_*\|_2}$.
		
		%A common example is the standard $\ell_2$-norm.
		%We will consider special norms in Section~\ref{sec:additive_error}.
		
		\item \emph{Local error}:
				$\max_{u \in V} \frac{|\rho_*(u) - \widehat{\rho}(u)|}{|\rho_*(u)|}$.
		
	\end{compactitem}
\end{definition}

From Definition~\ref{defn:error},
it is evident that if the vector $\widehat{\rho}$ achieves an $\epsilon$-multiplicative error for every coordinate, then its local error is at most $\epsilon$. Additionally, the local error is always greater than or equal to the global error.


\noindent \textbf{Number of Inversions.} The coordinates of the target vector~$\rho_* \in \R^V$ induce a total quasi-order on $V$, which might not be a total order because
two nodes might have the same density value.  
Given an approximate density vector~$\widehat{\rho}$,
approximate algorithms for the densest subset problem
or the density decomposition typically sort the nodes in non-increasing order of the coordinates,
where we assume that any tie is resolved in some pre-determined way, such as by the node name.
We use the number of inversions to quantify how much a permutation deviates
from the quasi-order induced by~$\rho_*$.

\begin{definition}[Number of Inversions]
\label{def:order1}
	The number of inversions 
	in a permutation 
	$\pi: V \rightarrow \{1, 2, \ldots, |V|\}$
	with respect to a target vector $\rho_* \in \R^V$
	is the size of the following set of unordered pairs:
	
	$\{ \{u, v \} \in {V \choose 2} : \pi(u) < \pi(v) \wedge \rho_*(u) > \rho_*(v)\}.$
\end{definition} 


Note that if $\{B_\ell\}_{\ell =1}^k$ is the partition of $V$ in the density
decomposition, then the maximum number 
of inversions with respect to~$\rho_*$ is: 
$\sum_{\{i,j\} \in {[k] \choose 2}} |B_i| \cdot |B_j|$.

On the other hand, if the number of inversions of a permutation
is 0, a greedy procedure (such as~\cite[Algorithm 3]{DBLP:conf/www/DanischCS17})
using PAVA~\cite{barlow1972statistical}
can return the exact density decomposition.


For an iterative method approximating the density vector, 
the global or local error may never reach 0. However, if the method converges to the correct target $\rho_*$, the number of inversions will eventually drop to 0. Thus, the number of inversions can serve as an indicator that the target has been reached, even though the correctness of the resulting decomposition will still need to be verified -- potentially using the method described 
in Section~\ref{sec:exact}.




\ignore{

Recall that our ultimate goal is to solve density decomposition problem approximately. So, if the approximate density vector can already produce an ordering, that is consistent with the density decomposition, then use Line 5,6,7 in Algorithm 3 in \cite{DBLP:conf/www/DanischCS17} can output the exact density decomposition. So, given a  approximate density vector, it's reasonable to evaluate how much it deviate from the "correct" ordering. This is captured by the following notion. 
}

%then the heuristic algorithm (Algorithm 3) in \cite{DBLP:conf/www/DanischCS17} can already 


\ignore{
	The main idea of our algorithms is to compute (or approximate) the density vector $\rho_*$ in Definition~\ref{def:decomposition}, from which the decomposition can be recovered by sorting the nodes in non-increasing order on the coordinates of $\rho_*$.
}


\ignore{
\noindent \textbf{Hyperedge Weights Allocation.}
Many algorithms for the density decomposition
in the literature maintain variables that indicate
how each hyperedge $e \in E$ distributes its weight $w(e)$ among its neighbors in $\mathcal{F}$.

We denote $\mathcal{A}(G) := \{\alpha \in \mathbb{R}^{\mathcal{F}}_+ : \forall e \in E, \sum_{u:(e,u) \in \mathcal{F}} \alpha_{e\to u} = w(e)\}$; in particular, $\alpha_{e\to u}$ is the weight received by node $u$ from hyperedge $e$. 

Observe that each $\alpha \in \mcal{A}(G)$ 
induces a density vector $\rho_\alpha \in \R^V$
given by 

$$\rho_\alpha(u) := \frac{\sum_{e \in E: (e,u) \in \mathcal{F}} \alpha_{e\to u}}{w(u)}.$$


Analagously,
we will also consider
node weights allocation


$\mathcal{B}(G) := \{\beta \in \mathbb{R}^{\mathcal{F}}_+ : \forall u \in V, \sum_{e:(e,u) \in \mathcal{F}} \beta_{u \to e} = w(u)\}$.
}


\ignore{
	Indeed, our algorithms maintain such an auxiliary vector and enforce the following invariant relating the density vector $\rho \in \mathbb{R}^V$ with the auxiliary vector $\alpha \in \mathcal{D}(G)$.
	
	\noindent \textit{Invariant Pair.} We say that $(\rho \in \mathbb{R}^V_+, \alpha \in \mathcal{D}(G))$ is an invariant pair, if for all $u \in V$, $\rho(u) = \frac{\sum_{e \in E: (e,u) \in \mathcal{F}} \alpha_{e\to u}}{w(u)}$.
}

